"""
æ ‘å½¢å·¥ä½œæµå¼•æ“ä½¿ç”¨ç¤ºä¾‹ - é›†æˆLangChain LLM

å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ›´æ–°åçš„å¼•æ“è¿›è¡ŒAIé©±åŠ¨çš„å·¥ä½œæµå¤„ç†
"""

import asyncio
import json
import os
import traceback
from datetime import datetime
from pathlib import Path

from workflow_engine.engines.tree.engine import TreeWorkflowEngine
from workflow_engine.engines.tree.types import TreeWorkflowConfig


async def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºAIé©±åŠ¨çš„å†…å®¹ç”Ÿäº§å·¥ä½œæµ"""

    # å®šä¹‰ä¸€ä¸ªAIå†…å®¹ç”Ÿäº§å·¥ä½œæµé…ç½®
    workflow_config: TreeWorkflowConfig = {
        "workflow_id": "ai_content_workflow_001",
        "workflow_name": "AIå†…å®¹ç”Ÿäº§å·¥ä½œæµ",
        "description": "åŸºäºLLMçš„æ™ºèƒ½å†…å®¹åˆ›ä½œå’Œä¼˜åŒ–æµç¨‹",
        "version": "1.0.0",
        "type": "tree",
        "nodes": {
            "start": {
                "id": "start",
                "name": "å¯åŠ¨èŠ‚ç‚¹",
                "description": "å·¥ä½œæµå¼€å§‹",
                "prompt": "",
                "node_type": "START",
                "input_config": {
                    "include_prompt": True,
                    "include_previous_output": True,
                },
            },
            "topic_analysis": {
                "id": "topic_analysis",
                "name": "è¯é¢˜åˆ†æ",
                "description": "åˆ†æç”¨æˆ·è¾“å…¥çš„è¯é¢˜ï¼Œæå–å…³é”®è¦ç´ å’Œç›®æ ‡å—ä¼—",
                "prompt": "è¯·åˆ†æä»¥ä¸‹è¯é¢˜ï¼Œæå–å…³é”®è¦ç´ ã€ç›®æ ‡å—ä¼—å’Œå†…å®¹æ–¹å‘ã€‚è¦æ±‚è¾“å‡ºç»“æ„åŒ–ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š1. æ ¸å¿ƒä¸»é¢˜ 2. ç›®æ ‡å—ä¼— 3. å†…å®¹è§’åº¦ 4. å…³é”®è¯å»ºè®®",
                "node_type": "INTERMEDIATE",
                "input_config": {
                    "include_prompt": True,
                    "include_previous_output": True,
                },
            },
            "content_outline": {
                "id": "content_outline",
                "name": "å†…å®¹å¤§çº²",
                "description": "åŸºäºè¯é¢˜åˆ†æç»“æœï¼Œç”Ÿæˆè¯¦ç»†çš„å†…å®¹å¤§çº²",
                "prompt": "åŸºäºä¸Šè¿°è¯é¢˜åˆ†æï¼Œè¯·ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„å†…å®¹å¤§çº²ã€‚åŒ…æ‹¬ï¼š1. æ ‡é¢˜å»ºè®® 2. ä¸»è¦ç« èŠ‚ 3. æ¯ç« èŠ‚çš„æ ¸å¿ƒè¦ç‚¹ 4. é¢„æœŸå­—æ•°åˆ†é…",
                "node_type": "INTERMEDIATE",
                "input_config": {
                    "include_prompt": True,
                    "include_previous_output": True,
                },
            },
            "content_generation": {
                "id": "content_generation",
                "name": "å†…å®¹ç”Ÿæˆ",
                "description": "æ ¹æ®å¤§çº²ç”Ÿæˆå®Œæ•´çš„æ–‡ç« å†…å®¹",
                "prompt": "æ ¹æ®ä»¥ä¸Šå¤§çº²ï¼Œè¯·ç”Ÿæˆå®Œæ•´çš„æ–‡ç« å†…å®¹ã€‚è¦æ±‚ï¼š1. é€»è¾‘æ¸…æ™° 2. è¯­è¨€æµç•… 3. ä¿¡æ¯å‡†ç¡® 4. ç¬¦åˆç›®æ ‡å—ä¼—éœ€æ±‚",
                "node_type": "INTERMEDIATE",
                "input_config": {
                    "include_prompt": True,
                    "include_previous_output": True,
                },
            },
            "seo_optimization": {
                "id": "seo_optimization",
                "name": "SEOä¼˜åŒ–",
                "description": "SEOä¼˜åŒ–å»ºè®®å’Œå…ƒæ•°æ®ç”Ÿæˆ",
                "prompt": "è¯·ä¸ºä»¥ä¸Šå†…å®¹æä¾›SEOä¼˜åŒ–å»ºè®®ï¼ŒåŒ…æ‹¬ï¼š1. æ ‡é¢˜ä¼˜åŒ– 2. å…³é”®è¯å¯†åº¦è°ƒæ•´ 3. Metaæè¿° 4. å†…é“¾å»ºè®® 5. å›¾ç‰‡altæ ‡ç­¾å»ºè®®",
                "node_type": "INTERMEDIATE",
                "input_config": {
                    "include_prompt": True,
                    "include_previous_output": True,
                },
            },
            "quality_review": {
                "id": "quality_review",
                "name": "è´¨é‡å®¡æ ¸",
                "description": "å†…å®¹è´¨é‡å®¡æ ¸å’Œæ”¹è¿›å»ºè®®",
                "prompt": "è¯·å¯¹ç”Ÿæˆçš„å†…å®¹è¿›è¡Œè´¨é‡å®¡æ ¸ï¼Œä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ï¼š1. å†…å®¹å‡†ç¡®æ€§ 2. é€»è¾‘å®Œæ•´æ€§ 3. è¯­è¨€è´¨é‡ 4. ç”¨æˆ·ä½“éªŒ 5. æ”¹è¿›å»ºè®®",
                "node_type": "INTERMEDIATE",
                "input_config": {
                    "include_prompt": True,
                    "include_previous_output": True,
                },
            },
            "final_output": {
                "id": "final_output",
                "name": "æœ€ç»ˆè¾“å‡º",
                "description": "æ•´åˆæ‰€æœ‰ç»“æœï¼Œç”Ÿæˆæœ€ç»ˆçš„å†…å®¹åŒ…",
                "prompt": "è¯·æ•´åˆä»¥ä¸Šæ‰€æœ‰å†…å®¹ï¼Œç”Ÿæˆæœ€ç»ˆçš„å†…å®¹äº¤ä»˜åŒ…ï¼ŒåŒ…æ‹¬ï¼š1. æœ€ç»ˆæ–‡ç«  2. SEOå…ƒæ•°æ® 3. è´¨é‡è¯„ä¼°æŠ¥å‘Š 4. å‘å¸ƒå»ºè®®",
                "node_type": "LEAF",
                "input_config": {
                    "include_prompt": True,
                    "include_previous_output": True,
                },
            },
        },
        "edges": [
            {
                "from_node": "start",
                "to_node": "topic_analysis",
                "condition": None,
            },
            {
                "from_node": "topic_analysis",
                "to_node": "content_outline",
                "condition": None,
            },
            {
                "from_node": "content_outline",
                "to_node": "content_generation",
                "condition": None,
            },
            {
                "from_node": "content_generation",
                "to_node": "seo_optimization",
                "condition": None,
            },
            {
                "from_node": "content_generation",
                "to_node": "quality_review",
                "condition": None,
            },
            {
                "from_node": "seo_optimization",
                "to_node": "final_output",
                "condition": None,
            },
            {
                "from_node": "quality_review",
                "to_node": "final_output",
                "condition": None,
            },
        ],
    }

    try:
        print("=" * 60)
        print("ğŸš€ å¯åŠ¨AIé©±åŠ¨çš„æ ‘å½¢å·¥ä½œæµå¼•æ“")
        print("=" * 60)

        # åˆå§‹åŒ–å·¥ä½œæµå¼•æ“
        engine = TreeWorkflowEngine(workflow_config)

        # æ‰§è¡Œå·¥ä½œæµ
        print("\nğŸ”„ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
        summary = await engine.execute_workflow()

        # è¾“å‡ºæ‰§è¡Œç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ“Š å·¥ä½œæµæ‰§è¡Œæ‘˜è¦")
        print("=" * 60)
        print(f"å·¥ä½œæµID: {summary.workflow_id}")
        print(f"å·¥ä½œæµåç§°: {summary.workflow_name}")
        print(
            f"å®Œæˆç‡: {summary.success_rate:.1%} ({summary.completed_count}/{summary.total_count})"
        )
        print(f"æ‰§è¡ŒçŠ¶æ€: {'âœ… å®Œå…¨æˆåŠŸ' if summary.is_complete else 'âš ï¸ éƒ¨åˆ†å®Œæˆ'}")

        # è¾“å‡ºå„èŠ‚ç‚¹ç»“æœ
        print(f"\nğŸ“ èŠ‚ç‚¹æ‰§è¡Œç»“æœ:")
        for node_id, result in summary.results.items():
            node_name = engine.nodes[node_id].name
            result_preview = (
                str(result)[:100] + "..." if len(str(result)) > 100 else str(result)
            )
            print(f"  â€¢ {node_name}: {result_preview}")

        # å¦‚æœæœ‰æœ€ç»ˆè¾“å‡ºèŠ‚ç‚¹ï¼Œå•ç‹¬æ˜¾ç¤º
        if "final_output" in summary.results:
            print(f"\nğŸ¯ æœ€ç»ˆå†…å®¹åŒ…:")
            print("-" * 40)
            final_result = summary.results["final_output"]
            print(final_result)

        # ä¿å­˜å®Œæ•´çš„å·¥ä½œæµç»“æ„å’Œæ‘˜è¦åˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path("workflow_outputs")
        output_dir.mkdir(exist_ok=True)

        # ä¿å­˜å·¥ä½œæµé…ç½®
        config_file = output_dir / f"ai_content_workflow_config_{timestamp}.json"
        with open(config_file, "w", encoding="utf-8") as f:
            json.dump(workflow_config, f, ensure_ascii=False, indent=2)

        # ä¿å­˜æ‰§è¡Œæ‘˜è¦å’Œç»“æœ
        summary_data = {
            "execution_info": {
                "workflow_id": summary.workflow_id,
                "workflow_name": summary.workflow_name,
                "execution_time": timestamp,
                "success_rate": summary.success_rate,
                "completed_count": summary.completed_count,
                "total_count": summary.total_count,
                "is_complete": summary.is_complete,
            },
            "node_results": {},
        }

        # æ·»åŠ æ¯ä¸ªèŠ‚ç‚¹çš„è¯¦ç»†ç»“æœ
        for node_id, result in summary.results.items():
            node_name = engine.nodes[node_id].name
            summary_data["node_results"][node_id] = {
                "node_name": node_name,
                "result": str(result),
            }

        summary_file = output_dir / f"ai_content_workflow_summary_{timestamp}.json"
        with open(summary_file, "w", encoding="utf-8") as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ å·¥ä½œæµæ•°æ®å·²ä¿å­˜:")
        print(f"  â€¢ é…ç½®æ–‡ä»¶: {config_file}")
        print(f"  â€¢ æ‘˜è¦æ–‡ä»¶: {summary_file}")

    except Exception as e:
        print(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        traceback.print_exc()


async def demo_conditional_workflow():
    """æ¼”ç¤ºå¸¦æ¡ä»¶åˆ†æ”¯çš„å·¥ä½œæµ"""

    conditional_config: TreeWorkflowConfig = {
        "workflow_id": "conditional_content_workflow",
        "workflow_name": "æ¡ä»¶åˆ†æ”¯å†…å®¹å·¥ä½œæµ",
        "description": "æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©ä¸åŒå¤„ç†è·¯å¾„",
        "version": "1.0.0",
        "type": "tree",
        "nodes": {
            "start": {
                "id": "start",
                "name": "å¯åŠ¨",
                "description": "å·¥ä½œæµå¼€å§‹",
                "prompt": "",
                "node_type": "START",
                "input_config": {
                    "include_prompt": True,
                    "include_previous_output": True,
                },
            },
            "content_classifier": {
                "id": "content_classifier",
                "name": "å†…å®¹åˆ†ç±»å™¨",
                "description": "åˆ†æå†…å®¹ç±»å‹å¹¶è¾“å‡ºåˆ†ç±»ç»“æœ",
                "prompt": 'è¯·åˆ†æè¾“å…¥å†…å®¹çš„ç±»å‹ï¼Œå¹¶æ˜ç¡®è¾“å‡ºåˆ†ç±»ç»“æœã€‚å¯èƒ½çš„ç±»å‹ï¼šæŠ€æœ¯æ–‡ç« ã€è¥é”€æ–‡æ¡ˆã€æ–°é—»æŠ¥é“ã€å­¦æœ¯è®ºæ–‡ã€‚è¯·åœ¨å›ç­”å¼€å¤´æ˜ç¡®è¯´æ˜ï¼š"å†…å®¹ç±»å‹ï¼š[å…·ä½“ç±»å‹]"',
                "node_type": "INTERMEDIATE",
                "input_config": {
                    "include_prompt": True,
                    "include_previous_output": True,
                },
            },
            "technical_processor": {
                "id": "technical_processor",
                "name": "æŠ€æœ¯æ–‡ç« å¤„ç†å™¨",
                "description": "ä¸“é—¨å¤„ç†æŠ€æœ¯ç±»å†…å®¹",
                "prompt": "ä½œä¸ºæŠ€æœ¯ä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹æŠ€æœ¯å†…å®¹è¿›è¡Œæ·±åº¦åˆ†æå’Œä¼˜åŒ–ï¼ŒåŒ…æ‹¬æŠ€æœ¯å‡†ç¡®æ€§æ£€æŸ¥ã€ä»£ç ç¤ºä¾‹ä¼˜åŒ–ã€æœ€ä½³å®è·µå»ºè®®ç­‰ã€‚",
                "node_type": "LEAF",
                "input_config": {
                    "include_prompt": True,
                    "include_previous_output": True,
                },
            },
            "marketing_processor": {
                "id": "marketing_processor",
                "name": "è¥é”€æ–‡æ¡ˆå¤„ç†å™¨",
                "description": "ä¸“é—¨å¤„ç†è¥é”€ç±»å†…å®¹",
                "prompt": "ä½œä¸ºè¥é”€ä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹è¥é”€å†…å®¹è¿›è¡Œä¼˜åŒ–ï¼ŒåŒ…æ‹¬å¸å¼•åŠ›æå‡ã€è½¬åŒ–ç‡ä¼˜åŒ–ã€å—ä¼—å®šä½åˆ†æç­‰ã€‚",
                "node_type": "LEAF",
                "input_config": {
                    "include_prompt": True,
                    "include_previous_output": True,
                },
            },
            "general_processor": {
                "id": "general_processor",
                "name": "é€šç”¨å¤„ç†å™¨",
                "description": "å¤„ç†å…¶ä»–ç±»å‹å†…å®¹",
                "prompt": "è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œé€šç”¨ä¼˜åŒ–ï¼ŒåŒ…æ‹¬ç»“æ„è°ƒæ•´ã€è¯­è¨€æ¶¦è‰²ã€é€»è¾‘å®Œå–„ç­‰ã€‚",
                "node_type": "LEAF",
                "input_config": {
                    "include_prompt": True,
                    "include_previous_output": True,
                },
            },
        },
        "edges": [
            {
                "from_node": "start",
                "to_node": "content_classifier",
                "condition": None,
            },
            {
                "from_node": "content_classifier",
                "to_node": "technical_processor",
                "condition": {
                    "match_target": "node_output",
                    "match_type": "contains",
                    "match_value": "æŠ€æœ¯æ–‡ç« ",
                    "case_sensitive": False,
                },
            },
            {
                "from_node": "content_classifier",
                "to_node": "marketing_processor",
                "condition": {
                    "match_target": "node_output",
                    "match_type": "contains",
                    "match_value": "è¥é”€æ–‡æ¡ˆ",
                    "case_sensitive": False,
                },
            },
            {
                "from_node": "content_classifier",
                "to_node": "general_processor",
                "condition": {
                    "match_target": "node_output",
                    "match_type": "not_contains",
                    "match_value": "æŠ€æœ¯æ–‡ç« ",
                    "case_sensitive": False,
                },
            },
        ],
    }

    print("\n" + "=" * 60)
    print("ğŸ”€ æ¼”ç¤ºæ¡ä»¶åˆ†æ”¯å·¥ä½œæµ")
    print("=" * 60)

    try:
        engine = TreeWorkflowEngine(conditional_config)
        summary = await engine.execute_workflow()

        print(f"\nâœ… æ¡ä»¶å·¥ä½œæµå®Œæˆï¼ŒæˆåŠŸç‡: {summary.success_rate:.1%}")

        # è¾“å‡ºå„èŠ‚ç‚¹ç»“æœ
        print(f"\nğŸ“ èŠ‚ç‚¹æ‰§è¡Œç»“æœ:")
        for node_id, result in summary.results.items():
            node_name = engine.nodes[node_id].name
            result_preview = (
                str(result)[:100] + "..." if len(str(result)) > 100 else str(result)
            )
            print(f"  â€¢ {node_name}: {result_preview}")

        # ä¿å­˜å®Œæ•´çš„å·¥ä½œæµç»“æ„å’Œæ‘˜è¦åˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path("workflow_outputs")
        output_dir.mkdir(exist_ok=True)

        # ä¿å­˜å·¥ä½œæµé…ç½®
        config_file = output_dir / f"conditional_workflow_config_{timestamp}.json"
        with open(config_file, "w", encoding="utf-8") as f:
            json.dump(conditional_config, f, ensure_ascii=False, indent=2)

        # ä¿å­˜æ‰§è¡Œæ‘˜è¦å’Œç»“æœ
        summary_data = {
            "execution_info": {
                "workflow_id": summary.workflow_id,
                "workflow_name": summary.workflow_name,
                "execution_time": timestamp,
                "success_rate": summary.success_rate,
                "completed_count": summary.completed_count,
                "total_count": summary.total_count,
                "is_complete": summary.is_complete,
            },
            "node_results": {},
        }

        # æ·»åŠ æ¯ä¸ªèŠ‚ç‚¹çš„è¯¦ç»†ç»“æœ
        for node_id, result in summary.results.items():
            node_name = engine.nodes[node_id].name
            summary_data["node_results"][node_id] = {
                "node_name": node_name,
                "result": str(result),
            }

        summary_file = output_dir / f"conditional_workflow_summary_{timestamp}.json"
        with open(summary_file, "w", encoding="utf-8") as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ æ¡ä»¶å·¥ä½œæµæ•°æ®å·²ä¿å­˜:")
        print(f"  â€¢ é…ç½®æ–‡ä»¶: {config_file}")
        print(f"  â€¢ æ‘˜è¦æ–‡ä»¶: {summary_file}")

    except Exception as e:
        print(f"âŒ æ¡ä»¶å·¥ä½œæµå¤±è´¥: {e}")


# ====================================================================
# æ–°å¢çš„åŒæ­¥åŒ…è£…å‡½æ•°ï¼Œä½œä¸ºå‘½ä»¤è¡Œå…¥å£ç‚¹
# ====================================================================
def cli_main():
    """
    åŒæ­¥çš„å‘½ä»¤è¡Œå…¥å£å‡½æ•°ã€‚
    å®ƒè´Ÿè´£æ£€æŸ¥ç¯å¢ƒå¹¶ä½¿ç”¨ asyncio.run() æ¥è¿è¡Œå¼‚æ­¥çš„æ¼”ç¤ºå‡½æ•°ã€‚
    """

    try:
        # è¿è¡Œä¸»æ¼”ç¤º
        asyncio.run(main())

        # è¿è¡Œæ¡ä»¶åˆ†æ”¯æ¼”ç¤º
        print("\n" + "ğŸ”„ ç»§ç»­æ¼”ç¤ºæ¡ä»¶åˆ†æ”¯å·¥ä½œæµ...")
        asyncio.run(demo_conditional_workflow())

        print("\nğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
    except KeyboardInterrupt:
        print("\næ“ä½œè¢«ç”¨æˆ·ä¸­æ–­ã€‚")
    except Exception as e:
        print(f"\nâŒ è„šæœ¬æ‰§è¡Œæ—¶å‘ç”Ÿæœªæ•è·çš„é”™è¯¯: {e}")
        traceback.print_exc()


# ====================================================================
# __main__ å—ç°åœ¨åªè°ƒç”¨åŒæ­¥çš„åŒ…è£…å‡½æ•°
# ====================================================================
if __name__ == "__main__":
    cli_main()

"""
æ ‘å½¢å·¥ä½œæµå¼•æ“å®ç°

åŸºäºåŸå§‹ç®€å•ç‰ˆæœ¬é‡æ„ï¼Œæ”¯æŒå¤šstartèŠ‚ç‚¹ï¼Œåœ¨å›¾æ„å»ºé˜¶æ®µè¿›è¡Œç¯è·¯æ£€æŸ¥
"""

import asyncio
import os
from typing import Dict, List, Any, Set, Optional
from collections import defaultdict

try:
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage
    from langchain_core.prompts import ChatPromptTemplate
    from dotenv import load_dotenv
    # Load environment variables from .env file
    load_dotenv()
except ImportError as e:
    # Fallback if langchain or dotenv not installed
    ChatOpenAI = None
    HumanMessage = None
    ChatPromptTemplate = None
    load_dotenv = None
    print(f"âš ï¸ å¯¼å…¥è­¦å‘Š: {e}")
    print("è¯·å®‰è£…ä¾èµ–: pip install langchain-openai python-dotenv")

from ...base.engine import BaseWorkflowEngine
from ...workflow_types import NodeType, ExecutionSummary, NodeExecutor
from .types import (
    TreeNode, TreeEdge, TreeInputConfig, DatabaseSearchInput,
    TreeExecutionStats, TreeExecutionSummary, TreeExecutionStrategy,
    TreeCycleError
)

class TreeWorkflowEngine(BaseWorkflowEngine):
    """æ ‘å½¢å·¥ä½œæµæ‰§è¡Œå¼•æ“
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. äº‹ä»¶é©±åŠ¨çš„èŠ‚ç‚¹æ‰§è¡Œ
    2. è‡ªåŠ¨ä¾èµ–æ£€æŸ¥å’Œå¹¶è¡Œæ‰§è¡Œ  
    3. çµæ´»çš„è¾“å…¥å†…å®¹ç»„åˆ
    4. å¤šåˆ†å‰è¾“å‡ºæ”¯æŒ
    5. æ”¯æŒå¤šä¸ªstartèŠ‚ç‚¹
    """
    
    def __init__(self, workflow_config: Dict[str, Any], node_executor: Optional[NodeExecutor] = None) -> None:
        """åˆå§‹åŒ–æ ‘å½¢å·¥ä½œæµå¼•æ“"""
        super().__init__(workflow_config)
        if node_executor:
            self.set_node_executor(node_executor)
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self._init_llm_client()
    
    def _initialize_from_config(self, config: Dict[str, Any]) -> None:
        """ä»é…ç½®åˆå§‹åŒ–æ ‘å½¢å¼•æ“"""
        # è§£æèŠ‚ç‚¹å’Œè¾¹
        self.nodes: Dict[str, TreeNode] = {
            node_id: TreeNode.from_dict(node_data) 
            for node_id, node_data in config['nodes'].items()
        }
        self.edges: List[TreeEdge] = [
            TreeEdge.from_dict(edge_data) 
            for edge_data in config['edges']
        ]
        
        # æ„å»ºæ‰§è¡Œå›¾å¹¶æ£€æŸ¥ç¯è·¯
        self.outgoing_edges = self._build_execution_graph()
    
    def _build_execution_graph(self) -> Dict[str, List[TreeEdge]]:
        """æ„å»ºæ‰§è¡Œå›¾ï¼ˆé‚»æ¥è¡¨ï¼‰å¹¶æ£€æŸ¥ç¯è·¯"""
        graph: Dict[str, List[TreeEdge]] = defaultdict(list)
        for edge in self.edges:
            graph[edge.from_node].append(edge)
        
        # åœ¨æ„å»ºæ—¶æ£€æŸ¥ç¯è·¯
        if self._has_cycle(graph):
            raise TreeCycleError("æ£€æµ‹åˆ°ç¯è·¯ï¼Œæ ‘å½¢å·¥ä½œæµä¸å…è®¸ç¯è·¯")
        
        return dict(graph)
    
    def _init_llm_client(self) -> None:
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ - 2025å¹´æœ€æ–°ç‰ˆæœ¬"""
        self.llm_client = None
        
        if ChatOpenAI is not None:
            # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­æ˜¯å¦æœ‰APIå¯†é’¥
            api_key = os.getenv('OPENAI_API_KEY')
            api_base = os.getenv('OPENAI_API_BASE', 'https://aiproxy.usw.sealos.io/v1')
            model_name = os.getenv('OPENAI_MODEL', 'claude-3-5-haiku-20241022')
            
            # æ¸…ç†URLï¼Œç§»é™¤å¯èƒ½çš„æ³¨é‡Š
            api_base = api_base.split('#')[0].strip()
            
            if api_key:
                try:
                    self.llm_client = ChatOpenAI(
                        temperature=0.7,
                        model=model_name,  # ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„æ¨¡å‹
                        max_tokens=500,
                        api_key=api_key,
                        base_url=api_base,  # ä½¿ç”¨æ¸…ç†åçš„ç«¯ç‚¹
                        timeout=30.0  # æ·»åŠ è¶…æ—¶è®¾ç½®
                    )
                    print("âœ… LangChain OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (2025ç‰ˆæœ¬)")
                    print(f"   æ¨¡å‹: {model_name}")
                    print(f"   APIç«¯ç‚¹: {api_base}")
                    print("   ä½¿ç”¨Sealosä»£ç† - Claudeæ¨¡å‹")
                except Exception as e:
                    print(f"âš ï¸ LangChain OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                    print("   å°†ä½¿ç”¨æ¨¡æ‹ŸLLMè°ƒç”¨")
            else:
                print("âš ï¸ æœªæ‰¾åˆ°OPENAI_API_KEYç¯å¢ƒå˜é‡")
                print("   è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®æˆ–è¿è¡Œ: export OPENAI_API_KEY='your-key'")
                print("   å°†ä½¿ç”¨æ¨¡æ‹ŸLLMè°ƒç”¨")
        else:
            print("âš ï¸ æœªå®‰è£…langchain-openaiåŒ…")
            print("   è¯·è¿è¡Œ: pip install -r requirements.txt")
            print("   å°†ä½¿ç”¨æ¨¡æ‹ŸLLMè°ƒç”¨")
    
    def _has_cycle(self, graph: Dict[str, List[TreeEdge]]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰ç¯è·¯ï¼ˆDFSæ£€æµ‹ï¼‰"""
        # çŠ¶æ€ï¼š0-æœªè®¿é—®ï¼Œ1-æ­£åœ¨è®¿é—®ï¼Œ2-å·²è®¿é—®
        state = {node_id: 0 for node_id in self.nodes.keys()}
        
        def dfs(node_id: str) -> bool:
            if state[node_id] == 1:  # æ­£åœ¨è®¿é—®ä¸­ï¼Œå‘ç°å›è¾¹
                return True
            if state[node_id] == 2:  # å·²è®¿é—®è¿‡
                return False
            
            state[node_id] = 1  # æ ‡è®°ä¸ºæ­£åœ¨è®¿é—®
            
            # è®¿é—®æ‰€æœ‰é‚»å±…
            for edge in graph.get(node_id, []):
                if dfs(edge.to_node):
                    return True
            
            state[node_id] = 2  # æ ‡è®°ä¸ºå·²è®¿é—®
            return False
        
        # å¯¹æ‰€æœ‰æœªè®¿é—®çš„èŠ‚ç‚¹è¿›è¡ŒDFS
        for node_id in self.nodes.keys():
            if state[node_id] == 0:
                if dfs(node_id):
                    return True
        
        return False
    
    async def execute_workflow(self) -> TreeExecutionSummary:
        """æ‰§è¡Œæ ‘å½¢å·¥ä½œæµ"""
        print(f"ğŸš€ æ‰§è¡Œå·¥ä½œæµ: {self.workflow_name} ({self.workflow_id})")
        
        # æ‰¾åˆ°æ‰€æœ‰èµ·å§‹èŠ‚ç‚¹
        start_nodes = [node_id for node_id, node in self.nodes.items() 
                      if node.node_type == NodeType.START]
        
        if not start_nodes:
            raise ValueError("æœªæ‰¾åˆ°èµ·å§‹èŠ‚ç‚¹")
        
        print(f"ğŸ¯ èµ·å§‹èŠ‚ç‚¹: {[self.nodes[nid].name for nid in start_nodes]}")
        
        # å¯åŠ¨æ‰€æœ‰èµ·å§‹èŠ‚ç‚¹
        for start_node_id in start_nodes:
            result = await self.node_executor(start_node_id, {})
            self._mark_node_completed(start_node_id, result)
            await self._try_trigger_next_nodes(start_node_id)
        
        # äº‹ä»¶é©±åŠ¨å¾ªç¯
        await self._run_execution_loop()
        
        print("âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼")
        
        # ç”Ÿæˆæ‰§è¡Œæ‘˜è¦
        base_summary = ExecutionSummary(
            workflow_id=self.workflow_id,
            workflow_name=self.workflow_name,
            completed_count=len(self.completed_nodes),
            total_count=len(self.nodes),
            results=self.node_results
        )
        
        return TreeExecutionSummary(
            base_summary=base_summary,
            stats=TreeExecutionStats(),
            execution_strategy=TreeExecutionStrategy.EVENT_DRIVEN
        )
    
    async def _run_execution_loop(self):
        """è¿è¡Œäº‹ä»¶é©±åŠ¨çš„æ‰§è¡Œå¾ªç¯"""
        while self.running_tasks:
            completed_task_ids = []
            for node_id, task in self.running_tasks.items():
                if task.done():
                    completed_task_ids.append(node_id)
                    
                    try:
                        result = await task
                        self._mark_node_completed(node_id, result)
                    except Exception as e:
                        print(f"âŒ èŠ‚ç‚¹ {self.nodes[node_id].name} æ‰§è¡Œå¤±è´¥: {e}")
                        self._mark_node_failed(node_id, e)
            
            # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡å¹¶è§¦å‘åç»­èŠ‚ç‚¹
            for node_id in completed_task_ids:
                del self.running_tasks[node_id]
                await self._try_trigger_next_nodes(node_id)
            
            # çŸ­æš‚ä¼‘çœ é¿å…å¿™ç­‰å¾…
            if self.running_tasks:
                await asyncio.sleep(0.1)
    
    async def _try_trigger_next_nodes(self, completed_node_id: str):
        """å°è¯•è§¦å‘åç»­èŠ‚ç‚¹"""
        outgoing_edges = self.outgoing_edges.get(completed_node_id, [])
        
        for edge in outgoing_edges:
            target_node_id = edge.to_node
            
            # æ£€æŸ¥æ¡ä»¶æ˜¯å¦æ»¡è¶³
            if not self.condition_checker(edge.condition, completed_node_id, self.node_results):
                continue
                
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å‰é©±èŠ‚ç‚¹éƒ½å·²å®Œæˆ
            if not self._check_all_prerequisites_completed(target_node_id):
                print(f"â³ èŠ‚ç‚¹ {self.nodes[target_node_id].name} ç­‰å¾…å‰é©±èŠ‚ç‚¹å®Œæˆ")
                continue
                
            # é¿å…é‡å¤æ‰§è¡Œ
            if target_node_id in self.running_tasks or target_node_id in self.completed_nodes:
                continue
            
            # å‡†å¤‡è¾“å…¥æ•°æ®å¹¶å¯åŠ¨ä»»åŠ¡
            input_data = self._prepare_node_input(target_node_id, edge)
            task = asyncio.create_task(self.node_executor(target_node_id, input_data))
            self.running_tasks[target_node_id] = task
            
            node = self.nodes[target_node_id]
            print(f"ğŸ”„ å¯åŠ¨èŠ‚ç‚¹: {node.name} ({node.description})")
    
    def _check_all_prerequisites_completed(self, node_id: str) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹çš„æ‰€æœ‰å‰é©±æ˜¯å¦éƒ½å·²å®Œæˆ"""
        prerequisites = set()
        
        # æ”¶é›†æ‰€æœ‰æŒ‡å‘è¯¥èŠ‚ç‚¹çš„å‰é©±
        for edge in self.edges:
            if edge.to_node == node_id:
                prerequisites.add(edge.from_node)
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å‰é©±éƒ½å·²å®Œæˆ
        missing_prereqs = prerequisites - self.completed_nodes
        if missing_prereqs:
            missing_names = [self.nodes[pid].name for pid in missing_prereqs]
            print(f"   ç­‰å¾…å‰é©±: {', '.join(missing_names)}")
            return False
        
        return True
    
    def _prepare_node_input(self, node_id: str, edge: TreeEdge) -> Dict[str, Any]:
        """æ ¹æ®è¾¹é…ç½®å‡†å¤‡èŠ‚ç‚¹è¾“å…¥"""
        node = self.nodes[node_id]
        input_config = edge.input_config
        input_data = {}
        
        # 1. ä»»åŠ¡æç¤ºè¯
        if input_config.include_prompt:
            input_data['prompt'] = node.prompt
        
         # 2. æ”¶é›†æ‰€æœ‰ç›´æ¥å‰é©±çš„è¾“å‡º - å…³é”®ä¿®æ­£
        if input_config.include_previous_output:
            # âœ… æ–°é€»è¾‘ï¼šæ ¹æ®node_idæ”¶é›†æ‰€æœ‰å‰é©±
            all_predecessors = self._get_all_completed_predecessors(node_id)
            # TODO: å¦‚æœæ²¡è·å–åˆ° all_predecessors éœ€è¦æŠ¥é”™
            if all_predecessors:
                input_data['previous_output'] = self._combine_predecessor_outputs(all_predecessors)
        
        # 3. æ•°æ®åº“æ£€ç´¢
        if input_config.include_database_search:
            if node.database_connection:
                search_input = self._prepare_database_search_input(
                    input_config.database_search_input,
                    input_data.get('prompt', ''),
                    input_data.get('previous_output', '')
                )
                input_data['database_search'] = {
                    'connection': node.database_connection,
                    'search_input': search_input
                }
        
        return input_data

    def _get_all_completed_predecessors(self, node_id: str) -> List[str]:
        """è·å–æŒ‡å®šèŠ‚ç‚¹çš„æ‰€æœ‰å·²å®Œæˆçš„ç›´æ¥å‰é©±èŠ‚ç‚¹
        
        Args:
            node_id: ç›®æ ‡èŠ‚ç‚¹ID
            
        Returns:
            å·²å®Œæˆçš„å‰é©±èŠ‚ç‚¹IDåˆ—è¡¨
        """
        predecessors = []
        
        # éå†æ‰€æœ‰è¾¹ï¼Œæ‰¾åˆ°æŒ‡å‘ç›®æ ‡èŠ‚ç‚¹çš„è¾¹
        for edge in self.edges:
            if (edge.to_node == node_id and 
                edge.from_node in self.completed_nodes):
                predecessors.append(edge.from_node)
        
        # å»é‡ä¿æŒé¡ºåºï¼ˆé¿å…é‡å¤è¾¹çš„æƒ…å†µï¼‰
        seen = set()
        unique_predecessors = []
        for pred_id in predecessors:
            if pred_id not in seen:
                seen.add(pred_id)
                unique_predecessors.append(pred_id)
        
        return unique_predecessors
    
    def _combine_predecessor_outputs(self, predecessor_ids: List[str]) -> str:
        """ç»„åˆå¤šä¸ªå‰é©±èŠ‚ç‚¹çš„è¾“å‡ºç»“æœ
        
        Args:
            predecessor_ids: å‰é©±èŠ‚ç‚¹IDåˆ—è¡¨
            
        Returns:
            ç»„åˆåçš„è¾“å‡ºå­—ç¬¦ä¸²
        """
        if not predecessor_ids:
            return ""
        
        # å•ä¸ªå‰é©±ï¼Œç›´æ¥è¿”å›ç»“æœ
        if len(predecessor_ids) == 1:
            return str(self.node_results[predecessor_ids[0]])
        
        # å¤šä¸ªå‰é©±ï¼Œç”¨æ ‡è¯†ç¬¦ç»„åˆ
        combined_parts = []
        for pred_id in predecessor_ids:
            pred_name = self.nodes[pred_id].name
            pred_result = self.node_results[pred_id]
            combined_parts.append(f"[{pred_name}]: {pred_result}")
        
        return " | ".join(combined_parts)
    
    def _prepare_database_search_input(self, search_type: DatabaseSearchInput, 
                                     prompt: str, previous_output: str) -> str:
        """å‡†å¤‡æ•°æ®åº“æ£€ç´¢çš„è¾“å…¥å†…å®¹"""
        if search_type == DatabaseSearchInput.PROMPT:
            return prompt
        elif search_type == DatabaseSearchInput.PREVIOUS_OUTPUT:
            return str(previous_output)
        elif search_type == DatabaseSearchInput.PROMPT_AND_PREVIOUS:
            parts = []
            if prompt:
                parts.append(f"æŒ‡ä»¤: {prompt}")
            if previous_output:
                parts.append(f"ä¸Šä¸‹æ–‡: {previous_output}")
            return " | ".join(parts)
        else:
            return prompt
    
    async def _default_node_executor(self, node_id: str, input_data: Dict[str, Any]) -> Any:
        """é»˜è®¤èŠ‚ç‚¹æ‰§è¡Œå™¨"""
        node = self.nodes[node_id]
        
        # èµ·å§‹èŠ‚ç‚¹ç›´æ¥è¿”å›
        if node.node_type == NodeType.START:
            return f"START_{self.workflow_id}"
        
        # ç»„è£…å¤„ç†è¾“å…¥
        input_parts = []
        
        if 'prompt' in input_data:
            input_parts.append(f"PROMPT: {input_data['prompt']}")
        
        if 'previous_output' in input_data:
            input_parts.append(f"PREV: {input_data['previous_output']}")
        
        if 'database_search' in input_data:
            db_result = await self.database_searcher(
                input_data['database_search']['connection'],
                input_data['database_search']['search_input']
            )
            input_parts.append(f"DB: {db_result}")
        
        # è°ƒç”¨å¤„ç†å‡½æ•°
        full_input = " | ".join(input_parts)
        return await self._mock_llm_call(node_id, full_input)
    
    async def _mock_llm_call(self, node_id: str, input_text: str) -> str:
        """æ™ºèƒ½LLMè°ƒç”¨ - æ”¯æŒçœŸå®OpenAIè°ƒç”¨å’Œæ¨¡æ‹Ÿè°ƒç”¨"""
        node_name = self.nodes[node_id].name
        print(f"   ğŸ¤– å¤„ç†ä¸­: {node_name}")
        
        # å¦‚æœæœ‰çœŸå®çš„LLMå®¢æˆ·ç«¯ï¼Œä½¿ç”¨çœŸå®è°ƒç”¨
        if self.llm_client and HumanMessage:
            try:
                # æ„å»ºä¼˜åŒ–çš„æç¤ºè¯æ¨¡æ¿ (2025å¹´æœ€ä½³å®è·µ)
                system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å·¥ä½œæµèŠ‚ç‚¹å¤„ç†å™¨ã€‚

ä»»åŠ¡ç¯å¢ƒ:
- å·¥ä½œæµåç§°: {self.workflow_name}
- èŠ‚ç‚¹åç§°: {node_name}
- èŠ‚ç‚¹ID: {node_id}
- èŠ‚ç‚¹æè¿°: {self.nodes[node_id].description}

è¯·æ ¹æ®è¾“å…¥æ•°æ®è¿›è¡Œå¤„ç†ï¼Œç”Ÿæˆç®€æ´ã€å‡†ç¡®ä¸”æœ‰ä»·å€¼çš„è¾“å‡ºç»“æœã€‚"""

                user_prompt = f"è¾“å…¥æ•°æ®: {input_text}"
                
                # ä½¿ç”¨æœ€æ–°çš„ChatPromptTemplate (å¦‚æœå¯ç”¨)
                if ChatPromptTemplate:
                    prompt_template = ChatPromptTemplate.from_messages([
                        ("system", system_prompt),
                        ("user", user_prompt)
                    ])
                    messages = prompt_template.format_messages()
                    response = self.llm_client.invoke(messages)
                else:
                    # å¤‡ç”¨æ–¹æ³•ï¼šç›´æ¥ä½¿ç”¨HumanMessage
                    full_prompt = f"{system_prompt}\n\n{user_prompt}"
                    response = self.llm_client.invoke([HumanMessage(content=full_prompt)])
                
                result = response.content.strip()
                
                # è®°å½•è°ƒç”¨ç»Ÿè®¡
                token_count = len(result.split())
                print(f"   âœ… OpenAIè°ƒç”¨æˆåŠŸ (~{token_count} tokens)")
                print(f"   ğŸ“„ ç»“æœé¢„è§ˆ: {result[:80]}..." if len(result) > 80 else f"   ğŸ“„ å®Œæ•´ç»“æœ: {result}")
                
                return result
                
            except Exception as e:
                print(f"   âŒ OpenAIè°ƒç”¨å¤±è´¥: {e}")
                print(f"   ğŸ”„ è‡ªåŠ¨é™çº§åˆ°æ¨¡æ‹Ÿè°ƒç”¨")
                # é™çº§åˆ°æ¨¡æ‹Ÿè°ƒç”¨
                pass
        
        # æ¨¡æ‹ŸLLMè°ƒç”¨
        await asyncio.sleep(0.5)
        
        # ç”Ÿæˆæ›´æ™ºèƒ½çš„æ¨¡æ‹Ÿå“åº”
        node = self.nodes[node_id]
        if node.node_type == NodeType.START:
            return f"å·²å¯åŠ¨å·¥ä½œæµ: {self.workflow_name}"
        elif node.node_type == NodeType.LEAF:
            return f"æœ€ç»ˆç»“æœæ¥è‡ª{node_name}: åŸºäºè¾“å…¥'{input_text[:30]}...' çš„å¤„ç†ç»“æœ"
        else:
            return f"{node_name}å¤„ç†ç»“æœ: åŸºäº'{input_text[:30]}...' ç”Ÿæˆçš„ä¸­é—´è¾“å‡º"
    
    async def _default_database_searcher(self, connection: str, search_input: str) -> str:
        """é»˜è®¤æ•°æ®åº“æ£€ç´¢å™¨"""
        print(f"   ğŸ” DBæŸ¥è¯¢: {connection}")
        await asyncio.sleep(0.2)
        return f"DB_RESULT_{connection}"
    
    def _mark_node_completed(self, node_id: str, result: Any) -> None:
        """é‡å†™ä»¥æä¾›æ ‘å½¢ç‰¹æœ‰çš„æ—¥å¿—"""
        super()._mark_node_completed(node_id, result)
        node = self.nodes[node_id]
        
        if node.node_type == NodeType.LEAF:
            print(f"ğŸ¯ å¶å­èŠ‚ç‚¹å®Œæˆ: {node.name}")
        elif node.node_type == NodeType.START:
            print(f"âœ“ èµ·å§‹èŠ‚ç‚¹å®Œæˆ: {node.name}")
        else:
            print(f"âœ“ èŠ‚ç‚¹å®Œæˆ: {node.name}") 